import numpy as np
import tensorflow as tf
import pandas as pd
import gc
import pyarrow.parquet as pq
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout, Input, Activation, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model, load_model
from sklearn import metrics
from scipy.stats import zscore
from sklearn.model_selection import KFold
from tensorflow.python.keras.callbacks import EarlyStopping


train = pd.read_parquet('../input/low-mem-parquet/train_low_mem.parquet')
df = train[:100000]
del train

# target
target = df['target']

# f_data
index = [f"f_{i}" for i in range(300)]
f_data = df[index]

target = target.astype("float16")
f_data = f_data.astype("float16")
del df

def build_model_1():
    input = Input(shape=(300,), name = 'input')
    hidden1 = Dense(256, activation = 'relu', name = 'dense1')(input)
    batch1 = BatchNormalization(trainable = True)(hidden1)
    hidden2 = Dense(256, activation = 'relu', name = 'dense2')(batch1)
    batch2 = BatchNormalization(trainable = True)(hidden2)
    dropout = Dropout(0.3)(batch2)
    hidden3 = Dense(128, activation = 'relu', name = 'dense3')(dropout)
    batch3 = BatchNormalization(trainable = True)(hidden3)
    output = Dense(1, name = 'output')(batch3)
    
    model = Model(inputs=[input], outputs=output)
    
    model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])
    
    return model
    
def kf_model_save(f_data, target):
    kf = KFold(4, shuffle=True, random_state = 111) # random_state = consistency
    
    oos_pred = []
    append_pred =[]
    mean_pred = []
    
    fold = 0
    for train_idx, val_idx in kf.split(f_data):
        fold+=1
        print(f"Fold #{fold}")

        x_train, x_val = f_data.loc[train_idx], f_data.loc[val_idx]
        y_train, y_val = target.loc[train_idx], target.loc[val_idx]

        model = build_model_1()
        #early_stopping = EarlyStopping(patience = 30)
        model.fit(x_train, y_train, batch_size=512, validation_data=(x_val, y_val), epochs = EPOCH)

        model.save(f"model_{fold}.h5")
        
def model_mean(test_df):    
    model_1 = load_model("model_1.h5")
    model_2 = load_model("model_2.h5")
    model_3 = load_model("model_3.h5")
    model_4 = load_model("model_4.h5")
    
    pred_1 = model_1.predict(test_df[:,2:].astype("float16"))
    pred_2 = model_2.predict(test_df[:,2:].astype("float16"))
    pred_3 = model_3.predict(test_df[:,2:].astype("float16"))
    pred_4 = model_4.predict(test_df[:,2:].astype("float16"))
    
    pred = (pred_1 + pred_2 + pred_3 + pred_4) / 4.0
    
    return pred

import ubiquant
env = ubiquant.make_env()   # initialize the environment
iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission

EPOCH = 10
kf_model_save(f_data, target)

for (test_df, sample_prediction_df) in iter_test:
    numpy_test_df=test_df.to_numpy()
    sample_prediction_df['target'] = model_mean(numpy_test_df)
    env.predict(sample_prediction_df)   # register your predictions
